#!/bin/bash

# Training script for SemKey Stage 2 text reconstruction model
# Flan-T5 with LoRA for EEG-to-text reconstruction
#
# Output directory structure:
#   ./logs/<experiment_name>_<timestamp>/
#     ├── tensorboard/    # TensorBoard logs
#     ├── checkpoints/    # Model checkpoints
#     ├── training.log    # Console output log
#     └── training_error.log  # Error log

# Set Hugging Face cache directory
export HF_HOME="./data/zuco_preprocessed_dataframe/hf_cache"
export TRANSFORMERS_CACHE="./data/zuco_preprocessed_dataframe/hf_cache"

# Create cache directory if it doesn't exist
mkdir -p "$HF_HOME"

# ============================================================================
# CONFIGURATION PARAMETERS
# ============================================================================

# Data
# Set DATA_PATH to use real dataset, leave empty ("") for mock data
# -> This should be the dataset generated by inference/predict_semkey_parallel_and_pack.py
DATA_PATH="./data/zuco_preprocessed_dataframe/....df"
BATCH_SIZE=72
NUM_WORKERS=4
SEED=42

# Label configuration
TOPIC_LABELS=("Biographies and Factual Knowledge" "Movie Reviews and Sentiment")
SENTIMENT_LABELS=("non_neutral" "neutral")

# Model Architecture
TEXT_MODEL="google/flan-t5-large"
FREEZE_STRATEGY="full_freeze_llm"  # Options: "lora" or "full_freeze_llm" or "full_trainable_llm"
LORA_RANK=8

# T5 prompt type
# Default to include all ("sentiment", "topic", "surprisal", "length")
# OR, use "sentiment_topic" to include "sentiment" and "topic" ...
PROMPT_TYPE=default

# Attention Mask Strategy
ATTENTION_MASK_TYPE="bidirectional"  # Options: "bidirectional" or "causal"

# Global EEG Feature
USE_EI=true  # Set to false to disable global EEG feature

# Zi EEG Feature (negative as no drop)
ZI_DROP_PROB=-10.0

# Projection Layer
USE_PROJECTOR=true  # Set to false to disable trainable projection layer

# Use metadata (prompts: dataset, task, subject)
USE_METADATA=false

# Label Embedding Initialization (Optional)
# Leave empty ("") to use random initialization
# Provide path to checkpoint containing pre-trained label embeddings
LABEL_EMBED_INIT=""

# Training
MAX_EPOCHS=15
PROJECTOR_LR=2e-4
LR=2e-4
MIN_LR=1e-6
WARMUP_EPOCHS=3
WEIGHT_DECAY=0.01

# Hardware
DEVICE="cuda:0"

# Logging
LOG_DIR="./logs/semkey_stage2"
EXPERIMENT_NAME="exp"

# ============================================================================

echo "=========================================="
echo "Stage 2 Training Configuration:"
echo "  Text Model: $TEXT_MODEL"
echo "  Freeze Strategy: $FREEZE_STRATEGY"
echo "  LoRA Rank: $LORA_RANK"
echo "  Attention Mask Type: $ATTENTION_MASK_TYPE"
echo "  Use Global EEG (ei): $USE_EI"
echo "  Zi Drop prob ( < 0 no drop ): $ZI_DROP_PROB"
echo "  Use Projection Layer: $USE_PROJECTOR"
if [ "$USE_PROJECTOR" = true ]; then
    echo "  Projector LR: $PROJECTOR_LR"
fi
echo "  Use Metadata: $USE_METADATA"
echo "  Prompt type: $PROMPT_TYPE"
if [ -n "$DATA_PATH" ]; then
    echo "  Data Path: $DATA_PATH"
    echo -n "  Sentiment Labels: "
    echo "${SENTIMENT_LABELS[@]}"
    echo -n "  Topic Labels :"
    echo "${TOPIC_LABELS[@]}"
else
    echo "  Data: Mock dataset"
    echo "  Data Size: $DATA_SIZE"
fi
echo "  Batch Size: $BATCH_SIZE"
echo "  Max Epochs: $MAX_EPOCHS"
echo "  Learning Rate: $LR (max), $MIN_LR (min)"
echo "  Warmup Epochs: $WARMUP_EPOCHS"
echo "  Weight Decay: $WEIGHT_DECAY"
echo "  Device: $DEVICE"
if [ -n "$LABEL_EMBED_INIT" ]; then
    echo "  Label Embed Init: $LABEL_EMBED_INIT"
else
    echo "  Label Embed Init: Random initialization"
fi
echo "=========================================="
echo

# Build command with optional label embedding argument
CMD="python -m train.train_stage2 \
    --batch_size $BATCH_SIZE \
    --num_workers $NUM_WORKERS \
    --max_epochs $MAX_EPOCHS \
    --lr $LR \
    --min_lr $MIN_LR \
    --warmup_epochs $WARMUP_EPOCHS \
    --weight_decay $WEIGHT_DECAY \
    --text_model \"$TEXT_MODEL\" \
    --freeze_strategy \"$FREEZE_STRATEGY\" \
    --lora_rank $LORA_RANK \
    --attention_mask_type \"$ATTENTION_MASK_TYPE\" \
    --device \"$DEVICE\" \
    --log_dir \"$LOG_DIR\" \
    --experiment_name \"$EXPERIMENT_NAME\" \
    --seed $SEED \
    --prompt_type \"$PROMPT_TYPE\" \
    --train_Zi_drop_prob $ZI_DROP_PROB" \

# Add use_ei flag
if [ "$USE_EI" = true ]; then
    CMD="$CMD --use_ei"
else
    CMD="$CMD --no_use_ei"
fi

# Add use_projector flag
if [ "$USE_PROJECTOR" = true ]; then
    CMD="$CMD --use_projector"
    CMD="$CMD --proj_lr \"$PROJECTOR_LR\""
else
    CMD="$CMD --no_projector"
fi

# Add use_metadata flag
if [ "$USE_METADATA" = true ]; then
    CMD="$CMD --use_metadata"
fi

# Add data path or data size
if [ -n "$DATA_PATH" ]; then
    CMD="$CMD --data_path \"$DATA_PATH\""
    CMD+=(--sentiment_labels "${SENTIMENT_LABELS[@]}")
    CMD+=(--topic_labels "${TOPIC_LABELS[@]}")
else
    CMD="$CMD --data_size $DATA_SIZE"
fi

# Add label embedding initialization if provided
if [ -n "$LABEL_EMBED_INIT" ]; then
    CMD="$CMD --label_embed_init \"$LABEL_EMBED_INIT\""
fi

# Execute command
eval $CMD